# Cattle Recognition Project - Phase 2.1 Status

## üìã FASE 2.1: DETECTION CAPABILITY TRAINING

### Objetivo de Fase 2.1
**Entrenamiento de Capacidad de Detecci√≥n**: Entrenar modelo especializado en localizar y dibujar bounding boxes alrededor de todo el ganado en una imagen o frame de video.

### Estado Actual
- [x] **Script de entrenamiento**: `scripts/train_phase_2_1.py` ‚úÖ **LISTO**
- [x] **Arquitectura definida**: YOLOv11 (Ultralytics) 
- [x] **Dataset preparado**: cattle-detection-v3 (formato YOLO)
- [ ] **Entrenamiento ejecutado**: Pendiente de ejecuci√≥n
- [ ] **Modelo entrenado**: `models/detection/best.pt` (pendiente)
- [ ] **Validaci√≥n completada**: M√©tricas de precisi√≥n pendientes

## üéØ Configuraci√≥n de Entrenamiento

### Arquitectura Implementada
- **Framework**: Ultralytics YOLOv11
- **Modelo base**: YOLOv11s (balance precisi√≥n/velocidad)
- **Input size**: 640x640 pixels
- **Clases**: 1 clase ("cattle")

### Par√°metros de Entrenamiento
```python
# Configuraci√≥n recomendada para Phase 2.1
model_size = "s"           # YOLOv11s (small) - balance √≥ptimo
epochs = 100               # Entrenamiento completo
batch_size = 16            # GPU memory friendly
imgsz = 640               # Standard YOLO input size
device = "cuda"           # GPU acceleration
```

### Dataset
- **Source**: cattle-detection-v3 (Roboflow)
- **Formato**: YOLO (images + labels .txt)
- **Estructura**: train/valid/test splits
- **Clases**: cattle (class 0)

## üöÄ Export Formats y Deployment Strategy

### üì¶ Formatos de Exportaci√≥n Disponibles

#### 1. **ONNX** (Recomendado por defecto)
```bash
--export-format onnx
```

**‚úÖ Ventajas:**
- **Cross-platform**: ARM, x86, diferentes OS
- **Optimizado para edge devices**: Raspberry Pi, Jetson Nano
- **Memory efficient**: ~100-200MB vs ~500MB PyTorch
- **Inference speed**: 2-3x m√°s r√°pido que PyTorch .pt
- **Runtime ligero**: ONNXRuntime vs framework completo
- **Standarizado**: Compatible con m√∫ltiples frameworks

**‚ùå Desventajas:**
- **Debugging limitado**: Menos herramientas de debug
- **Feature completeness**: Algunas operaciones avanzadas no soportadas
- **Versioning**: Compatibilidad entre versiones ONNX

**üéØ Ideal para:**
- Raspberry Pi deployment
- Dispositivos embebidos
- Drones con CPU ARM
- Production con memoria limitada

#### 2. **PyTorch (.pt)** 
```bash
--export-format pytorch
```

**‚úÖ Ventajas:**
- **Full compatibility**: 100% compatible con entrenamiento
- **Debugging completo**: Todas las herramientas PyTorch
- **Flexibilidad**: Modificaciones en tiempo real
- **Ecosistema completo**: Acceso a todas las funciones

**‚ùå Desventajas:**
- **Memory footprint**: ~500MB framework + modelo
- **Slower inference**: Sin optimizaciones de deployment
- **Dependencies**: Requiere PyTorch completo instalado
- **Platform specific**: Menos portabilidad

**üéØ Ideal para:**
- Development y testing
- Servidores con recursos abundantes
- Cuando necesitas debugging completo
- Prototipado r√°pido

#### 3. **TensorRT** (GPU optimizado)
```bash
--export-format tensorrt
```

**‚úÖ Ventajas:**
- **Maximum performance**: Inferencia m√°s r√°pida posible
- **GPU optimization**: Optimizado espec√≠ficamente para NVIDIA
- **INT8 quantization**: Reducci√≥n dram√°tica de memoria
- **Kernel fusion**: Optimizaciones autom√°ticas

**‚ùå Desventajas:**
- **NVIDIA only**: Funciona solo en GPUs NVIDIA
- **Platform specific**: No portable
- **Setup complexity**: Instalaci√≥n compleja TensorRT
- **Size limitations**: Funciona solo con modelos peque√±os-medianos

**üéØ Ideal para:**
- Servidores con GPUs NVIDIA potentes
- Applications que requieren m√°ximo rendimiento
- Procesamiento de m√∫ltiples streams simult√°neos

#### 4. **TensorFlow Lite (.tflite)**
```bash
--export-format tflite
```

**‚úÖ Ventajas:**
- **Mobile optimized**: Dise√±ado para smartphones/tablets
- **Ultra lightweight**: M√≠nimo memory footprint
- **Quantization**: INT8, FP16 optimizations
- **Mobile frameworks**: Android/iOS integration

**‚ùå Desventajas:**
- **Limited ops**: Operaciones soportadas limitadas
- **Conversion issues**: Puede fallar con modelos complejos
- **Performance**: Puede ser m√°s lento que ONNX en edge devices

**üéØ Ideal para:**
- Aplicaciones m√≥viles (Android/iOS)
- Microcontroladores
- Dispositivos con memory/power constraints extremos

#### 5. **CoreML** (Apple ecosystem)
```bash
--export-format coreml
```

**‚úÖ Ventajas:**
- **Apple optimized**: M√°ximo rendimiento en devices Apple
- **Neural Engine**: Aprovecha NPU en devices modernos
- **iOS/macOS integration**: Integraci√≥n nativa

**‚ùå Desventajas:**
- **Apple only**: Exclusivo ecosistema Apple
- **Limited flexibility**: Menos control sobre optimizaciones

**üéØ Ideal para:**
- Apps iOS/macOS exclusivamente
- Cuando tienes Neural Engine disponible

## üéØ Deployment Strategy por Escenario

### ü§ñ Raspberry Pi / Edge Devices
```bash
# Configuraci√≥n √≥ptima para Raspberry Pi
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size n \                    # YOLOv11n (nano) m√°s ligero
  --epochs 100 \
  --batch-size 32 \
  --device cuda \                     # Entrenar en GPU, deploy en CPU
  --export-format onnx                # Formato optimizado
```

**Justificaci√≥n:**
- **Model size "n"**: YOLOv11n (nano) es el m√°s ligero (~6MB)
- **ONNX**: Mejor rendimiento en CPU ARM
- **Memory**: <200MB total usage
- **Inference**: ~100-200ms por frame

### ‚òÅÔ∏è Cloud/Server Deployment
```bash
# Configuraci√≥n para servidores potentes
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size l \                    # YOLOv11l (large) m√°xima precisi√≥n
  --epochs 100 \
  --batch-size 16 \
  --device cuda \
  --export-format tensorrt            # M√°ximo rendimiento GPU
```

**Justificaci√≥n:**
- **Model size "l"**: M√°xima precisi√≥n para decisiones cr√≠ticas
- **TensorRT**: Aprovecha al m√°ximo GPUs NVIDIA
- **Memory**: Resources abundantes disponibles
- **Inference**: ~10-20ms por frame

### üì± Mobile Applications
```bash
# Configuraci√≥n para aplicaciones m√≥viles
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size n \                    # Modelo m√°s ligero
  --epochs 100 \
  --batch-size 32 \
  --device cuda \
  --export-format tflite             # Optimizado para m√≥viles
```

**Justificaci√≥n:**
- **TensorFlow Lite**: Dise√±ado espec√≠ficamente para m√≥viles
- **Size constraints**: Apps tienen l√≠mites de tama√±o
- **Battery**: Optimizado para consumo energ√©tico

### üöÅ Drone/UAV Deployment
```bash
# Configuraci√≥n para drones
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size s \                    # Balance precisi√≥n/velocidad
  --epochs 100 \
  --batch-size 16 \
  --device cuda \
  --export-format onnx                # Portable y eficiente
```

**Justificaci√≥n:**
- **Model size "s"**: Balance entre precisi√≥n y velocidad
- **ONNX**: Funciona en diferentes autopilot systems
- **Real-time**: Necesita procesamiento fluido para navegaci√≥n

## üìä Performance Comparison

### Inference Speed (por frame)
| Formato | Raspberry Pi 4 | Jetson Nano | NVIDIA RTX 3080 | iPhone 12 |
|---------|----------------|-------------|-----------------|-----------|
| PyTorch (.pt) | ~500ms | ~200ms | ~15ms | N/A |
| ONNX | ~200ms | ~100ms | ~25ms | ~50ms |
| TensorRT | N/A | ~50ms | ~8ms | N/A |
| TensorFlow Lite | ~300ms | ~150ms | N/A | ~30ms |
| CoreML | N/A | N/A | N/A | ~25ms |

### Memory Usage (modelo + runtime)
| Formato | Memory Footprint | Modelo Size |
|---------|------------------|-------------|
| PyTorch (.pt) | ~500MB | ~14MB |
| ONNX | ~150MB | ~14MB |
| TensorRT | ~300MB | ~8MB (optimizado) |
| TensorFlow Lite | ~50MB | ~6MB (quantized) |
| CoreML | ~80MB | ~12MB |

## üîß Comando de Entrenamiento Recomendado

### Para Raspberry Pi (Deployment final)
```bash
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size n \
  --epochs 100 \
  --batch-size 32 \
  --device cuda \
  --export-format onnx
```

### Para M√°ximo Performance (GPU servers)
```bash
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size s \
  --epochs 100 \
  --batch-size 16 \
  --device cuda \
  --export-format tensorrt
```

### Para Development/Testing
```bash
python scripts/train_phase_2_1.py \
  --dataset data/detection/cattle-detection-v3 \
  --model-size s \
  --epochs 100 \
  --batch-size 16 \
  --device cuda \
  --export-format pytorch
```

## üéØ Pr√≥ximos Pasos

### Immediate (Phase 2.1 completion)
1. **Ejecutar entrenamiento**: Correr script con configuraci√≥n elegida
2. **Validar modelo**: Verificar m√©tricas mAP, precision, recall
3. **Test deployment format**: Verificar que exportaci√≥n funciona
4. **Performance testing**: Medir inference speed en target device

### Integration (Phase 4 preparation)
1. **Combine with Phase 1.2**: Integrar con modelo de identificaci√≥n
2. **Pipeline testing**: Probar detecci√≥n ‚Üí identificaci√≥n
3. **Threshold calibration**: Optimizar par√°metros de similarity
4. **Real-time validation**: Probar en video streams

## üìù Decisi√≥n de Export Format

### Recomendaci√≥n por Defecto: **ONNX**

**Raz√≥n principal**: 
El proyecto est√° dise√±ado para **Raspberry Pi deployment** seg√∫n CLAUDE.md, y ONNX ofrece el mejor balance de:
- ‚úÖ Performance en edge devices
- ‚úÖ Cross-platform compatibility  
- ‚úÖ Memory efficiency
- ‚úÖ Future flexibility

**Cambio f√°cil**: El export format es configurable, permitiendo cambiar para diferentes deployment targets sin reentrenar.

---
**Estado del Proyecto**: ‚è≥ **Fase 2.1 PREPARADA PARA EJECUCI√ìN**
**Pr√≥ximo hito**: Ejecutar entrenamiento y completar Phase 2.1
**Integration ready**: Script listo para generar modelo compatible con Phase 1.2